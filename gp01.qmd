---
title: "Analyzing 311 Service Delivery Across NYC's Income Divide"
subtitle: "STA 9750 Final Project - Mid-Semester Check-In"
author: 
  - "Kyle Shaddox"
  - "Reem Hussein" 
  - "Hyacinthe Sarr"
  - "Juan Jaimes"
  - "Shahria Ahmed"
date: "`r Sys.Date()`"
execute:
  warning: false
  message: false
  echo: true
---

```{r setup, include=FALSE}
# Set CRAN mirror for package installation (must be first)
options(repos = c(CRAN = "https://cran.rstudio.com/"))

# Load required libraries
library(tidyverse)
library(httr2)
library(jsonlite)
library(sf)
library(leaflet)
library(plotly)
library(corrplot)
library(viridis)
library(DT)
library(scales)
library(lubridate)
library(broom)
library(knitr)
library(patchwork)

# Fix margin conflict between randomForest and ggplot2
margin <- ggplot2::margin

# Set options
options(scipen = 999)
knitr::opts_chunk$set(
  fig.align = "center",
  cache = TRUE,
  cache.lazy = FALSE
)
```

# Executive Summary

**Research Question:** Does NYC provide faster and more effective 311 service responses to wealthier neighborhoods compared to lower-income communities?

**Key Findings:** [To be completed after analysis]

# 1. Introduction and Motivation

## Problem Statement

The 311 system serves as New York City's primary non-emergency service request platform, handling millions of complaints annually ranging from noise violations to sanitation issues. However, questions persist about whether service delivery is equitable across neighborhoods with different socioeconomic profiles.

## Research Significance

Understanding disparities in 311 service delivery is crucial for:
- Ensuring equitable municipal service provision
- Identifying areas needing improved resource allocation
- Informing policy decisions about urban service delivery
- Promoting environmental and social justice

## Overarching Question

**Does NYC provide faster and more effective 311 service responses to wealthier neighborhoods compared to lower-income communities?**

# 2. Literature Review and Prior Art

## Previous Research

```{r literature-setup}
# Placeholder for literature review synthesis
# Key themes to address:
# - Urban service delivery equity studies
# - 311 system analysis in other cities
# - Socioeconomic factors in municipal services
# - Digital divide and service access patterns
```

**Key Findings from Literature:**
- [To be completed with actual literature review]
- Studies on urban service equity
- Analysis of 311 systems in other major cities
- Research on digital divide impacts on service access

## Research Gap

Our analysis contributes to existing literature by:
- Providing post-pandemic analysis of NYC 311 services
- Examining multiple complaint types across all five boroughs
- Using updated property valuation data for neighborhood wealth assessment
- Implementing predictive modeling for service delivery patterns

# 3. Data Sources and Methodology

## Primary Data Sources

### 3.1 NYC 311 Service Requests (2010-Present)
```{r data-311-info}
# Data source information
cat("Data Source: NYC Open Data\n")
cat("URL: https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/\n")
cat("Description: Comprehensive database of all 311 service requests\n")
cat("Key Variables: Location, complaint type, resolution time, status\n")
```

### 3.2 311 Resolution Satisfaction Survey
```{r data-satisfaction-info}
# Data source information  
cat("Data Source: NYC Open Data\n")
cat("URL: https://data.cityofnewyork.us/City-Government/311-Resolution-Satisfaction-Survey/5ijn-vbdv\n")
cat("Description: Customer satisfaction ratings for resolved 311 requests\n")
cat("Key Variables: Resolution satisfaction scores, feedback\n")
```

### 3.3 Property Valuation and Assessment Data
```{r data-property-info}
# Data source information
cat("Data Source: Data.gov\n") 
cat("URL: https://catalog.data.gov/dataset/property-valuation-and-assessment-data-db7c2\n")
cat("Description: Property values and assessments by neighborhood\n")
cat("Key Variables: Property values, assessment data, geographic identifiers\n")
```

## Data Acquisition

### 3.1 Load 311 Service Request Data
```{r}
#| code-fold: true
#| code-summary: "show historical jobs"
#| message: false
#| warning: false

library(httr2)
library(jsonlite)
library(dplyr)
library(DT)

# Function to download data from Socrata API using httr2 (replaces RSocrata)
download_socrata_data <- function(base_url, where_clause = NULL, limit = 50000) {
  # Build the URL with query parameters
  url <- base_url
  params <- list(`$limit` = limit)
  if (!is.null(where_clause)) {
    params[["$where"]] <- where_clause
  }
  
  # Make the request
  resp <- request(url) |>
    req_url_query(!!!params) |>
    req_perform()
  
  # Parse JSON response
  data <- resp |> resp_body_json(simplifyVector = TRUE)
  
  return(as_tibble(data))
}

# Define the file path where you'll save the data
data_file <- "nyc_311_data_2024_jan_apr.rds"

# Check if the file already exists
if (file.exists(data_file)) {
  # If it exists, just read it
  df <- readRDS(data_file)
} else {
  # If it doesn't exist, download it
  # Note: We download in chunks due to API limits
  
  base_url <- "https://data.cityofnewyork.us/resource/erm2-nwe9.json"
  where_clause <- "created_date>='2024-01-01T00:00:00' AND created_date<'2024-05-01T00:00:00'"
  
  # Download data (getting first 50000 rows - increase limit or paginate for more)
  df <- download_socrata_data(base_url, where_clause, limit = 50000)
  
  # Save to file
  saveRDS(df, data_file)
}

# Display first 1000 rows only
datatable(head(df, 1000),
          options = list(
            pageLength = 10,
            scrollX = TRUE,
            autoWidth = TRUE,
            columnDefs = list(list(targets = "_all", defaultContent = ""))
          ),
          filter = 'top',
          class = 'cell-border stripe',
          caption = "Showing first 1,000 rows of data")
```

### 3.2 Load Property Valuation Data
```{r load-property-data}
# Function to load property data
load_property_data <- function() {
  # For development - create sample property data with better structure
  set.seed(42)  # For reproducible results
  sample_property <- tibble(
    neighborhood = paste("Neighborhood", 1:100),
    borough = sample(c("Manhattan", "Brooklyn", "Queens", "Bronx", "Staten Island"), 100, replace = TRUE),
    median_property_value = pmax(100000, rnorm(100, 500000, 200000)),  # Ensure positive values
    median_income = pmax(25000, rnorm(100, 75000, 30000)),             # Ensure positive values
    latitude = runif(100, 40.4, 40.9),
    longitude = runif(100, -74.3, -73.7)
  ) |>
  # Ensure no missing values
  filter(!is.na(median_property_value), !is.na(median_income))
  
  return(sample_property)
}

# Load property data
df_property <- load_property_data()

cat("Property Data Loaded:\n")
cat("Rows:", nrow(df_property), "\n")
cat("Median Property Value Range: $", 
    paste(scales::comma(range(df_property$median_property_value, na.rm = TRUE)), collapse = " - "), "\n")
```

### 3.3 Data Quality Assessment
```{r data-quality}
# Assess data quality for 311 data
assess_data_quality <- function(df, dataset_name) {
  cat("=== Data Quality Assessment:", dataset_name, "===\n")
  
  # Missing values
  missing_summary <- df |>
    summarise(across(everything(), ~sum(is.na(.)))) |>
    pivot_longer(everything(), names_to = "variable", values_to = "missing_count") |>
    mutate(missing_percent = round(missing_count / nrow(df) * 100, 2)) |>
    arrange(desc(missing_percent))
  
  print(missing_summary)
  
  # Data completeness
  cat("\nOverall Completeness:", 
      round((1 - sum(is.na(df)) / (nrow(df) * ncol(df))) * 100, 2), "%\n\n")
}

# Assess both datasets
assess_data_quality(df, "311 Service Requests")
assess_data_quality(df_property, "Property Data")
```

## Data Processing and Cleaning

### 3.4 Clean and Process 311 Data
```{r clean-311-data}
# Clean and process 311 data
df_311_clean <- df |>
  # Remove rows with missing essential information
  filter(!is.na(latitude), !is.na(longitude), !is.na(created_date)) |>
  
  # Parse dates if they're character
 mutate(
    created_date = if(is.character(created_date)) ymd_hms(created_date, tz = "America/New_York", quiet = TRUE) else created_date,
    closed_date = if(is.character(closed_date)) ymd_hms(closed_date, tz = "America/New_York", quiet = TRUE) else closed_date
  ) |>
  
  # Calculate response time
  mutate(
    response_time_days = as.numeric(difftime(closed_date, created_date, units = "days")),
    year = year(created_date),
    month = month(created_date),
    weekday = wday(created_date, label = TRUE),
    # Categorize complaint types
    complaint_category = case_when(
      str_detect(complaint_type, "Noise") ~ "Noise",
      str_detect(complaint_type, "Parking|Driveway") ~ "Parking",
      str_detect(complaint_type, "Sanitation|Condition") ~ "Sanitation",
      TRUE ~ "Other"
    )
  ) |>
  
  # Filter for reasonable response times (remove outliers)
  filter(response_time_days >= 0 & response_time_days <= 365) |>
  
  # Clean borough names
  mutate(borough = str_to_title(borough))

cat("Cleaned 311 Data:\n")
cat("Rows after cleaning:", nrow(df_311_clean), "\n")
cat("Response time range:", round(range(df_311_clean$response_time_days, na.rm = TRUE), 2), "days\n")
```

```{r}
df_311_clean <- df_311_clean |>
  mutate(
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude)
  )
```

```{r}
df_property <- df_property |>
  mutate(
    latitude = as.numeric(latitude),
    longitude = as.numeric(longitude)
  )
```

### 3.5 Integrate Geographic Data
```{r geographic-integration}
# Create spatial data and integrate with property information
# This would typically involve spatial joins with census tracts or neighborhoods

# For demonstration - assign neighborhoods based on proximity
assign_neighborhoods <- function(df_311, df_property) {
  # Simple nearest neighbor assignment (in practice, use proper spatial joins)
  df_with_neighborhoods <- df_311 |>
    rowwise() |>
    mutate(
      # Find closest neighborhood (simplified calculation)
      neighborhood = {
        distances <- sqrt((latitude - df_property$latitude)^2 + (longitude - df_property$longitude)^2)
        df_property$neighborhood[which.min(distances)]
      }
    ) |>
    ungroup()
  
  # Join with property data - make sure to preserve borough from 311 data
  df_integrated <- df_with_neighborhoods |>
    left_join(df_property |> select(-borough), by = "neighborhood") |>  # Remove borough from property to avoid conflicts
    rename(borough_311 = borough) |>  # Keep original borough from 311 data
    rename(borough = borough_311)     # Use 311 borough as primary
  
  return(df_integrated)
}

# Integrate data
df_integrated <- assign_neighborhoods(df_311_clean, df_property)

cat("Integrated Dataset:\n")
cat("Rows:", nrow(df_integrated), "\n")
cat("Unique Neighborhoods:", length(unique(df_integrated$neighborhood)), "\n")
cat("Columns:", paste(names(df_integrated), collapse = ", "), "\n")
cat("Unique Boroughs:", paste(unique(df_integrated$borough), collapse = ", "), "\n")
```

# 4. Exploratory Data Analysis

## 4.1 Overall 311 Service Patterns
```{r eda-overview}
# Basic statistics
summary_stats <- df_integrated |>
  summarise(
    total_requests = n(),
    avg_response_time = round(mean(response_time_days, na.rm = TRUE), 2),
    median_response_time = round(median(response_time_days, na.rm = TRUE), 2),
    sd_response_time = round(sd(response_time_days, na.rm = TRUE), 2)
  )

kable(summary_stats, caption = "Overall 311 Service Request Statistics")

# Complaint type distribution
complaint_dist <- df_integrated |>
  count(complaint_category, sort = TRUE) |>
  mutate(percentage = round(n / sum(n) * 100, 1))

ggplot(complaint_dist, aes(x = reorder(complaint_category, n), y = n, fill = complaint_category)) +
  geom_col() +
  geom_text(aes(label = paste0(n, " (", percentage, "%)")), hjust = -0.1) +
  coord_flip() +
  labs(
    title = "Distribution of 311 Complaint Types",
    x = "Complaint Category",
    y = "Number of Requests",
    caption = "Data: NYC Open Data"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

# Complaint Types

```{r}
#| code-fold: true
#| code-summary: "show complaints type"
#| message: false
#| warning: false
library(dplyr)
library(ggplot2)
library(scales)
library(stringr)

# Aggregate by complaint_type
complaint_summary <- df %>%
  group_by(complaint_type) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Convert complaint_type to Title Case for readability
complaint_summary <- complaint_summary %>%
  mutate(complaint_type = str_to_title(complaint_type))

# Plot top 15 complaint types with labels
ggplot(complaint_summary %>% slice_max(count, n = 15),
       aes(x = reorder(complaint_type, count), y = count)) +
  geom_col(fill = "#2E86C1", width = 0.7) +
  geom_text(aes(label = comma(count)),
            hjust = -0.05, size = 3.5, family = "sans") +
  coord_flip(clip = "off") +  # allow labels to go past plot area
  scale_y_continuous(labels = comma, expand = expansion(mult = c(0, 0.15))) +
  labs(
    title = "Top 15 Complaint Types (Jan–Apr 2024)",
    x = "Complaint Type",
    y = "Number of Complaints"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
    axis.title.y = element_text(margin = ggplot2::margin(r = 10)),
    plot.margin = ggplot2::margin(10, 40, 10, 10)  # extra space on right for labels
  )
```

# Complaints by Borough
```{r}
#| code-fold: true
#| code-summary: "show complaints by borough"
#| message: false
#| warning: false

# Aggregate by borough
library(dplyr)
library(ggplot2)
library(scales)
library(stringr)

mako_colors <- c("#0D0887", "#6A00A8", "#B12A90", "#E16462", "#FCA636", "#F0F921")
# Aggregate by borough
borough_summary <- df %>%
  group_by(borough) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  mutate(borough = str_to_title(borough))  # title case

# Plot
ggplot(borough_summary,
       aes(x = count, y = reorder(borough, count), fill = borough)) +
  geom_col(width = 0.6, show.legend = FALSE) +
  geom_text(aes(label = comma(count)),
            hjust = -0.05, size = 4, family = "sans") +  # data labels
  scale_fill_manual(values = mako_colors) +
  scale_x_continuous(labels = comma, expand = expansion(mult = c(0, 0.15))) +  # fix scientific notation
  labs(
    title = "311 Complaints by Borough (Jan–Apr 2024)",
    x = "Number of Complaints",
    y = "Borough"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
    axis.title.y = element_text(margin = ggplot2::margin(r = 10)),
    plot.margin = ggplot2::margin(10, 40, 10, 10)  # extra space for labels
  ) +
  coord_cartesian(clip = "off")  # allow data labels to extend past plot area
```

# Location Types
```{r}
#| code-fold: true
#| code-summary: "show location type"
#| message: false
#| warning: false

# Aggregate by location_type
library(dplyr)
library(ggplot2)
library(scales)
library(stringr)

mako_colors <- c("#0D0887", "#6A00A8", "#B12A90", "#E16462", "#FCA636", "#F0F921")

# Aggregate by location_type
location_summary <- df %>%
  filter(!is.na(location_type) & location_type != "") %>%
  group_by(location_type) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice_head(n = 10) %>%  # Top 10 location types
  mutate(location_type = str_to_title(location_type))

# Plot
ggplot(location_summary,
       aes(x = count, y = reorder(location_type, count), fill = location_type)) +
  geom_col(width = 0.6, show.legend = FALSE) +
  geom_text(aes(label = comma(count)),
            hjust = -0.05, size = 4, family = "sans") +
  scale_x_continuous(labels = comma, expand = expansion(mult = c(0, 0.15))) +
  labs(
    title = "Top 10 Location Types (Jan–Apr 2024)",
    x = "Number of Complaints",
    y = "Location Type"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
    axis.title.y = element_text(margin = ggplot2::margin(r = 10)),
    plot.margin = ggplot2::margin(10, 40, 10, 10)
  ) +
  coord_cartesian(clip = "off")
```

# Average Resolution by Borough

```{r fig.height=6, fig.width=8}
#| code-fold: true
#| code-summary: "show average resolution"
#| message: false
#| warning: false

library(dplyr)
library(ggplot2)
library(lubridate)
library(scales)
library(stringr)

mako_colors <- c("#0D0887", "#6A00A8", "#B12A90", "#E16462", "#FCA636", "#F0F921")

# Ensure date columns are in POSIXct format
df <- df %>%
  mutate(
    created_date = ymd_hms(created_date, tz = "America/New_York", quiet = TRUE),
    closed_date = ymd_hms(closed_date, tz = "America/New_York", quiet = TRUE)
  )

# Create a new column: time to resolve in days
df <- df %>%
  mutate(
    resolution_time_days = as.numeric(difftime(closed_date, created_date, units = "days"))
  )

# Remove NA or unspecified boroughs
df_clean <- df %>%
  filter(!is.na(borough) & borough != "Unspecified" & !is.na(resolution_time_days))

# Compute average resolution time by borough
borough_resolution <- df_clean %>%
  group_by(borough) %>%
  summarise(avg_resolution_days = mean(resolution_time_days, na.rm = TRUE)) %>%
  mutate(borough = str_to_title(borough))

# Scatter plot
ggplot(borough_resolution, aes(x = reorder(borough, avg_resolution_days), y = avg_resolution_days)) +
  geom_point(size = 4, color = "#E74C3C") +
  geom_text(aes(label = round(avg_resolution_days, 1)),
            vjust = -0.8, size = 4) +
  scale_fill_manual(values = mako_colors) +
  labs(
    title = "Average Resolution Time by Borough (Days)",
    x = "Borough",
    y = "Average Resolution Time (Days)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5),  # centered title
    axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
    axis.title.y = element_text(margin = ggplot2::margin(r = 10))
  )
```

## 4.2 Geographic Distribution
```{r eda-geographic}
# Response times by borough
borough_stats <- df_integrated |>
  filter(!is.na(borough)) |>  # Remove any rows with missing borough
  group_by(borough) |>
  summarise(
    request_count = n(),
    avg_response_time = round(mean(response_time_days, na.rm = TRUE), 2),
    median_response_time = round(median(response_time_days, na.rm = TRUE), 2),
    median_property_value = round(mean(median_property_value, na.rm = TRUE), 0),
    .groups = "drop"
  ) |>
  arrange(desc(avg_response_time))

kable(borough_stats, caption = "311 Service Statistics by Borough")

# Visualization - also filter for non-missing borough
p1 <- df_integrated |>
  filter(!is.na(borough)) |>
  ggplot(aes(x = borough, y = response_time_days, fill = borough)) +
  geom_boxplot() +
  labs(
    title = "Response Time Distribution by Borough",
    x = "Borough",
    y = "Response Time (Days)"
  ) +
  theme_minimal() +
  theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))

p2 <- ggplot(borough_stats, aes(x = reorder(borough, avg_response_time), y = avg_response_time, fill = borough)) +
  geom_col() +
  geom_text(aes(label = paste0(avg_response_time, " days")), hjust = -0.1) +
  coord_flip() +
  labs(
    title = "Average Response Time by Borough",
    x = "Borough",
    y = "Average Response Time (Days)"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

p1 / p2
```

---

*This document was generated using Quarto. For questions about this analysis, please contact the project team.*
